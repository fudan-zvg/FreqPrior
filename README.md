# FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise

[![Paper](https://img.shields.io/badge/arXiv-Paper-b31b1b?logo=arxiv&logoColor=b31b1b)](https://arxiv.org/abs/2502.03496)

This repository is the official implementation of the following paper:

> **FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise**
> Yunlong Yuan, Yuanfan Guo, Chunwei Wang, Wei Zhang, Hang Xu, Li Zhang

<div>
    <h4 align="center">
        <img src="./assets/teaser.gif">
    </h4>
</div>


## üõ†Ô∏è Pipeline
<div align="center">
  <img src="assets/pipeline.png"/>
</div><br/>

We introduce FreqPrior, an effective approach to enhancing the quality of videos generated by diffusion models.
Our method features a novel frequency filtering technique specifically designed for Gaussian noise,
which is fundamentally a random variable rather than a signal.
FreqPrior requires no additional training, introduces no learnable parameters, and can be seamlessly integrated into any video diffusion model.

## :hammer: Quick Start

### Clone the Repository
```
git clone https://github.com/fudan-zvg/FreqPrior.git
cd FreqPrior
cd examples/AnimateDiff
```

### Prepare Environment
```
conda env create -f environment.yaml
conda activate animatediff
```

### Download Checkpoints
Please refer to the [official repo](https://github.com/guoyww/AnimateDiff) of AnimateDiff. The setup guide is listed [here](https://github.com/guoyww/AnimateDiff/blob/main/__assets__/docs/animatediff.md).

### Inference with FreqPrior
After downloading the base model, motion module and personalize T2I checkpoints, run the following command to generate animations with FreqPrior. The generation results is then saved to `outputs` folder.
```
python -m scripts.animate_with_freqprior \
    --config "configs/prompts/freqprior_examples/RealisticVision_v2.yaml" \
    --num_iters 3 \
    --ratio 0.8 \
    --mid_step 321 \
    --save_intermediate \
    --use_fp16
```

### Numerical Results
We perform theoretical analysis on several methods and conduct numerical experiments to validate our findings.
The numerical results can be obtained by running the script *covariance_error.py*. Use the following command: 
```
python covariance_error.py --filter [FILTER TYPE] --shape [(T, H, W)]
```

## :fountain_pen: BibTex
``` bibtex
@inproceedings{yuan2025freqprior,
  title={FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise},
  author={Yunlong Yuan and Yuanfan Guo and Chunwei Wang and Wei Zhang and Hang Xu and Li Zhang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025}
}
```

## Acknowledgement
The example code is built upon [FreeInit](https://github.com/TianxingWu/FreeInit) and [AnimateDiff](https://github.com/guoyww/AnimateDiff). Thanks to the team for their impressive work!